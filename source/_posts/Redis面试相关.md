---
title: Redis面试相关
date: 2021-06-02 22:23:12
categories: 面试篇
tags: [Redis]
---



#### Redis的基本数据类型和使用场景

* string  （自定义的SDS，simple dynamic string）
* list
* set
* hash
* zset （底层的数据结构是跳表，增删查的时间复杂度和红黑树一致，都是logn，但是这个进行比较查询比红黑树快很多，而且不需要进行红黑树平衡的节点旋转）

//todo 使用场景补充



<!-- more -->

#### Redis的持久化

##### RDB

(默认) 快照的方式，fork一个子进程定期将数据转换为占用空间小的快照（例如每十分钟）,dump.rdb文件，使用的具体指令是bgsave，恢复数据快

##### AOF

将执行过的指令都存到一个aof文件里面，如果指令过多，恢复数据的效率很慢，但是顶多损坏一秒钟的数据



#### 数据过期策略和内存淘汰机制

##### 过期策略

> Redis是使用**定期删除**和**惰性删除**两者配合的过期策略。

**定期删除**：默认每个100ms就随机抽取设置了过期时间的key，判断是否过期，过期就删除。因为key太多，全盘扫描会耗费很多时间，所以是随机抽取，但是这样的策略不够完善，需要惰性删除来配合。

**惰性删除**：客户端获取某个key，redis会检测是否过期，是，则删除并且不会返回给客户端。



##### 内存淘汰机制

由于以上两种过期策略都无法解决redis使用内存过高问题，所以有了下面的内存淘汰机制。

- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。**默认策略**
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。



#### 如何保证内存中的数据都是热数据

这个其实考验的是Redis的6种内存淘汰机制，我们可以将内存淘汰机制设置为allkeys-lru或者volatile-lru。

具体的操作是到redis的配置文件里面修改以下属性：

> maxmemory-policy volatile-lru



#### Redis中的事务

Redis支持部分事务，但是不满足像mysql数据库定义的事务的四大特性ACID，不满足的部分是强一致性。

相关的指令：

- MULTI：开启一个事务，MULTI 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中。
- EXEC：执行队列中所有的命令。
- DISCARD：清空事务队列,并放弃执行事务。
- UNWATCH：取消 WATCH 命令对所有 key 的监视。
- WATCH key1 key2 … ：监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。



#### keys和scan指令

使用keys 和scan可以扫出指定模式的key。

但是由于Redis是单线程的，keys指令会导致线程阻塞一段时间，如果是线上环境，建议使用scan指令，scan指令可以无阻塞的取出符合条件的key，但是会有一定的重复概率，需要客户端再进行一次去重，效率会比keys慢。



#### 为什么Redis是单线程，但是又能支撑高并发

因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，多线程会增加一个上下文切换的消耗和锁的竞争条件，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。在Redis6.0加入多线程，从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:

* 提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式
*  使用多线程充分利用多核，典型的实现比如 Memcached。

协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因：

* 可以充分利用服务器 CPU 资源，目前主线程只能利用一个核
*  多线程任务可以分摊 Redis 同步 IO 读写负荷

**总结**：

- 操作的数据都是在内存里面
- 单线程，没有上下文的切换消耗资源
- NIO多路复用机制



#### 如何保证Redis和数据库的双写一致性

- 懒加载模式缓存可采取双删+TTL失效来实现；
- 双删失败情况下可采取重试措施，重试有业务通过mq重试以及组件消费mysql的binlog再写入mq重试两种方式；
- 主动加载由于操作本身不具有幂等性，所以需要考虑加载的有序性问题，采取mq的分区机制实现串行化处理，实现缓存和mysql数据的最终一致，此时读和写操作的缓存加载事件是走的同一个mq。





#### 使用Redis的分布式锁（基于Redission，看门狗的使用）

具体指令就是SETNX(SET IF NOT EXIST)：尝试给某个key赋值，如果key不存在则赋值成功，并返回1，如果赋值不成功则返回0；设置成功后会给这个key设置过期时间。

看门狗的作用：有可能业务时间大于-锁的过期时间，这时候就会导致事务无法提交；看门狗能给占有的锁自动续期，保证业务完成之后能够正常释放持有的Redis锁。看门狗就是单独开了一条线程去不断延长锁的过期时间，也可以设置最长的锁持有时间。



![redission](2020051600372545.png)



#### Redission和Zookeeper实现的分布式锁对比

Redission

​		优点：redis性能很高，适合高并发下的加锁机制

​		缺点：如果加锁的redis master 故障，刚好数据也还没有同步到slave，那其他加锁的客户端则会再次加锁成功，则相当于有两个客户大都拿到了锁。



而zookeeper的分布式锁实现一般是由框架curator实现

![curator](20200516010224632.png)

第一个客户端发起申请锁，判断是否为第一个临时顺序节点，如果是，则加锁成功。
其他客户端按顺序创建后续的节点，判断是否为第一个节点，如果不是，加锁失败。同时对上一个节点进行监听，如果上一个节点被删除（释放锁），则会反向通知该客户端来获取锁。这里不能都监听第一个节点等待释放锁，因为如果都监听第一个节点，该节点一旦释放锁，则会全部通知监听该节点的客户端，引起不必要大量的网络开销，也就是羊群效应
基于zk通过创建临时顺序节点监听机制，可以反向通知客户端重新获取锁，是目前非常规范分布式锁解决方案，实时性也非常好。
但是zk加锁也会有一个问题，那就是假如说客户端1加锁成功后，由于网络原因，暂时无法收到心跳，则zk会判断改客户端已经死亡，会主动释放改顺序节点，并通知下一个客户端来获取锁，也就会造成有两个客户端同时拿到锁。这就类似于因为网络原因，造成有两个master的脑裂是同样的问题。

综上：分布式锁，使用zk会更专业，但是如果需要高并发处理，则redis会更合适。



#### 如何实现Redis的高可用

##### 哨兵模式

sentinel，哨兵是redis集群中非常重要的一个组件，主要有以下功能：

* 集群监控：负责监控redis master和slave进程是否在正常工作。
* 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
* 故障转移：如果master node宕机了，会自动转移到slave node上。
* 配置中心：如果发生了故障转移，通知client客户端新的master地址。

哨兵用于实现redis集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。

* 故障转移时，判断一个master node是否宕机，需要大部分的哨兵统一才行，这里涉及到了raft协议分布式一致性实现的分布式选举。
* 即使部分哨兵节点挂了，哨兵集群还是能正常工作。
* 哨兵通常需要3个以上的实例，来保证集群的健壮性。
* 哨兵+redis主从的部署架构，是不保证数据零丢失的，只能保证 redis集群的高可用性。



##### 集群模式

Redis cluster是一种服务端的sharding技术，3.0版本开始正式提供。采用slot（槽）的概念，一共划分为16384个槽，将请求发送到任意节点，接收到请求的节点将查询请求发送到的正确的节点上。

方案说明：

* 通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽，默认分配了16384个槽位。
* 每份数据分片会存储在多个互为主从的多节点上。
* 数据先写入主节点，再同步到从节点(支持配置为阻塞同步模式)。
* 同一分片多个节点间的数据不保持强一致性。
* 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点。
* 扩容时，需要把旧节点的数据迁移一部分到新节点。

在集群模式下，每个redis要开放两个端口号（不固定，可自定义），一个是6379，另一个是16379。

16379端口号是用来进行节点通信的，也就是cluster bus的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus用了另外一种二进制协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。



**优点**

* 无中心架构，支持动态扩容，对业务透明。
* 具备Sentinel的监控和自动Failover（故障转移）的能力。
* 客户端不需要连接集群所有节点，连接集群中任意一个可用节点即可。
* 高性能，客户端直连redis服务，免去了proxy代理的损耗。

**缺点**

* 运维也很复杂，数据迁移需要人工干预
* 只能使用0号数据库
* 不支持批量操作(pipeline管道操作)
* 分布式逻辑和存储模块耦合





#### 如何处理Redis中的热key、big key

##### BigKey

BigKey指的是redis中一些key value值很大，这些Key在序列化和反序列化过程中花费的时间很长，操作bigkey通常比较好使，意味着阻塞Redis可能性大，占用的流量也会变得很大。

**如何查看redis中的bigkey**:

```shell
redis-cli -h 127.0.0.1 -p 6379 --bigkeys
/*
该命令使用scan方式对Key进行统计，无序担心对redis造成阻塞
*/
```

![bigkeys](20201025121220395.png)

* summary给出了每种数据结构中的最大的key
* 统计中只有string类型的size单位是字节长度
* list,set,zset是以元素个数作为衡量标准，根据阿里标准，这些集合最大不要超过5000



**如何优化：**

优化的原则，如果是string类型减少字符串长度，list、hash、set、zset等减少成员数。

string长度大于10k，list长度大于10240认为是big key



##### 热key

热key指的是一段时间内访问频次比较高额的键值，大量的访问可能会把网卡带宽打满，也有可能导致redis宕机。

**如何发现热key**：

方法一：凭借业务经验，进行预估那些是热key

有一定的可行性，比如说商品在做秒杀，商品的key就可以判断为是热key;缺点很明显，准确性不高。

方法二：在客户端收集

在操作redis之前，加入代码进行数据统计发送到计算系统。缺点会对客户端代码造成入侵。

方法三：在proxy层收集

proxy可以使Twemproxy，在proxy层做收集上报。缺点是redis集群架构可能不做proxy。

方法四：用redis自带命令

* monitor，该命令可以实时抓取出redis服务器接收到的命令，然后再代码里面统计出热key，也有现成的分析工具比如redis-faina。缺点该命令在高并发环境下，会占用不少内存，降低redis的性能。
* redis-li --hotkeys，redis4.0.3提供了redis-cli的热点key发现功能。缺点如果key比较多，执行起来会比较慢。

方法五：自己抓包评估

redis客户端使用tcp协议和服务端进行交互，通信协议采用的是RESP(Redis Serialization Protocol)，自己写程序监听端口，按照RESP协议规则解析数据进行分析。缺点是开发成本高，维护困难。



**如何解决**：

* 做二级缓存，比如说HashMap，guava，caffeine，在发现了热key之后把数据缓存到JVM内存中，应用做集群架构，可以做好流量支撑，足以应付。
* 备份热key，就是把key在多个redis上都存一份，有热key请求进来，在备份的redis节点中随机选一个。

